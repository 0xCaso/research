\subsection{Networking}\label{sec:networking}

In the above sections we talk abstractly about nodes sending data to another
node or other set of nodes, without being too specific as to how this is
achieved. We do this to simplify the model and to clearly delineate a
separation of concerns between different layers. Of course, in a real-world
decentralised system the networking part also has to be decentralised - it is
no good if all communication passes through a few central servers, even if the
protocol running on top of it is decentralised within itself. As a concrete example on why this is the case: in certain security models, including
the traditional Byzantine fault-tolerant setting, nodes are modelled as capable
of being malicious but no consideration is given to malicious edges. Under
these models, if an edge is malicious in practice in the real-world, it is the
corresponding node(s) that is treated as malicious in the model. If the
underlying communications network is centralised, this effectively gives the
central parties the ability to "corrupt" a large number (e.g. $> 1/3$) of nodes
within this model, breaking its security, even if they don't actually have
arbitrary execution rights on that many nodes. In this section we outline and
enumerate the specific sending primitives that we require in Polkadot, and
sketch a high-level design on how we achieve these in a decentralised way, with
the specifics to be refined as we move forward with a production system.

Polkadot needs networking for a number of its components as follows.
\begin{enumerate}
\item accepting transactions from users for (a) parachains and (b) the relay chain
\item collation of blocks within a parachain
\item validation of parachain blocks, via proofs and attestation, and making these efficiently available \ref{sec:validity-and-availability}
\item distributing relay chain blocks \ref{sec:relaychainblockproduction} and votes \ref{sec:grandpa}
\item sending messages between different parachains \ref{sec:XCMP}
\item synchronising new state for (a) parachains and (b) the relay chain
\end{enumerate}

1(a), 2 and 3(a) are strictly outside of the scope of Polkadot, being entirely chosen by each parachain for themselves, but schemes similar to the ones described below (to be used by the relay chain) may also be used by parachains if they decide they are suitable.

\subsubsection{Message flows}

Generally speaking, the communication data flow follows these patterns:

\begin{itemize}
\item messages within a parachain and within the relay chain are gossipped
\item messages between a parachain and the relay chain are sent to some non-specific targets, e.g. a parachain validators to some collators, or a collator to some parachain validators. Gossip within the target set then propagates the messages to the entire target set.
\item messages from users to submit transactions are sent to some non-specific targets, e.g. collators or validators
\item as a special case, the erasure coded scheme for availability is sent directly from parachain validators to specific other validators. The scheme is design specifically to handle unreliability in the direct-sending primitive, which is generally harder to achieve reliability for than gossip or non-specific sending to a subset.
\end{itemize}

\subsubsection{Authentication and discovery} \label{sec:auth_discovery}

In secure protocols in general, and likewise with Polkadot, entities refer to each other by their cryptographic public keys. There is no strong security association with weak references such as IP addresses since those are typically controlled not by the entities themselves but by their communications provider.

Nevertheless in order to communicate we need some sort of association between entities and their addresses. In Polkadot we use a similar scheme as many other blockchains do, that is using the widely used distributed hash table (DHT), Kademlia \cite{Maymounkov:2002:Kademila}. Kademlia is a DHT that uses XOR distance metric for finding a node and is often used for networks with high churn. We use Protocols Labs' libp2p libraries \cite{} Kademlia implementation with some changes for this purpose. To prevent Eclipse attacks \cite{eclipseattack} we allow for routing tables that are large enough to contain at least some honest nodes.

Currently, this "address book" service is also used as the primary discovery mechanism - nodes perform random lookups on the space of keys when they join the network, and connect to whichever set of addresses are returned. Likewise, nodes accept any incoming connections. This makes it easy to support light clients and other unprivileged users, but also makes it easy to perform DoS attacks.

It is planned to develop a stronger authentication mechanism, where nodes authenticate themselves - their cryptographic identities and their roles as part of Polkadot - and verify other nodes both when (a) connections are mode, and when (b) looking up new nodes in the address book. Furthermore it should be possible to discover nodes that match a particular role, e.g. "collator for parachain C" and so on. Nevertheless it is also important to retain the ability to accept incoming connections from unauthenticated entities, e.g. users submitting transactions, or previously-privileged nodes that have been offline for a while that now want to synchronise, and this needs to be restricted on a resource basis, without starving the authenticated entities.

\subsubsection{Gossiping} \label{sec:gossiping}
The main idea of gossiping is to broadcast every newly received message in the nodes local network (peers that the node is aware of). Moreover, we apply some restriction to the gossiping protocol to prevent bandwidth problems, e.g., denial-of-service (DoS-ed) as follows. Currently a naive flooding approach is implemented, with various plans to make this more secure and efficient later on, which can be done independently of other components.

For GRANDPA we only allow two votes being received for each type of vote, round number, and voter. Any further votes will be ignored. For block production only valid block producers are allowed to produce one block per round and further blocks will be ignored.

We use \emph{Sentry nodes} that are proxy servers who receive all the traffic that would go to a certain validator and forward the traffic as soon as the validator is able to receive it.

We also plan to implement some sort of set reconciliation protocol to reduce redundancy when many senders attempt to send the same object to the same recipient at once.

\subsubsection{Specific and non-specific direct sending}

In the naive initial version this simply involves looking up a particular key in the address book and connecting to that address.

For specific-target direct sending, the only higher-layer protocol in Polkadot that requires this primitive is the erasure coded availability protocol, which is designed to handle the case where some of the nodes are actually unreachable.

For non-specific target direct sending, we have a few issues to consider:

\begin{itemize}
\item How to store and lookup non-specific targets in the address book in a secure and balanced way, and what the representation of the query term(s) should be.
\item Load-balancing actual transport-layer connection attempts over the whole target set, and ensuring availability.
\end{itemize}

As a special case, the source may already be a member of the target set, e.g. in an XCMP message the source parachain may share members with the target parachain. In this case, these members may bypass the above process entirely, and gossip between the two sets. However it may not be obvious to other members of the source set that the intersection member(s) are all online, and so they likely will want to attempt the process anyways.

\subsubsection{Message types}
Below we give an overview of where and how each type of message is sent. The column \emph{Nets} refers to the networks where a type of message is traversing and the column \emph{Mode} refers to the type of  routing. The column \emph{Static DHT Prefixes} refers to the DHT prefixes of the receivers if we use a one DHT for all and use prefixes to separate sub-networks.

We use gossiping mainly when the message type is small. For example, GRANDPA votes and attestation are very small. For bigger data structures we need to either use bloom filters or use direct routing.


