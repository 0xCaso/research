
\section{Protocol} % Availability and Validity
\label{sec:protocol}

We now describe and instantiate our {\em availability and validity protocol} that provides efficient sharding.  It consists of 
\begin{itemize}
\item a parachain phase that prepares the candidate block and performs preliminary validity checks,
\item a relay chain submission phase that distributes candidate parachain blocks and produces relay chain blocks,
\item availability and unavailability subprotocols that enforce availability in GRANDPA and BABE respectively,
\item fuller secondary validity checks for GRANDPA, and
\item finally, objection procedures for fishermen.
\end{itemize}

% TODO: Anything more worth saying here?  Maybe extract from:  The parachain phase is executed between collators and parachain validators. In the end of this phase, the parachain validators validate the block and provide its erasure code pieces to the validators. Then, the relay chain phase begins. If the parachain phase is executed correctly, then the relay chain phase includes extra validation of a parachain block, adding the block header to the relay chain and finalizing that relay chain block. Otherwise, unavailability protocol is run between validators. The details are as follows: 


\subsection{Parachain phase} 

We first describe the protocol by which collators of a parachain $\para$ submit a candidate block to the parachain validators assigned to $\vals_\para$.

\smallskip
% \paragraph{Collator subphase:} 

Initially a {\bf collator} $C$ of a parachain $\para$ must proposes some candidate block $B$ for $\para$.  We let $B'$ denotes the parent of $B$ and again let $\rin$ and $\rout$ denote state root before and after executing $B$.  

First, $C$ constructs the witness data $\pi$ by evaluating the block with $\prove_{\hat{\para}}(B,M)$, so they can build the candidate blob $\blobB = (B,\pi,M)$, and also obtain the block metadata $(H(B'),\rin,\rout)$.  

As $\prove$ is a randomized algorithm, $C$ must next reevaluate the block with $\verify_{\hat{\para}}(\blobB)$.  We shall assume verification succeeds, but if this verification fails then $C$ reports invalid parachain code for $\para$, and discards $B$ or possibly shuts down.  Assuming no errors, $C$ sends the candidate blob $\blobB$ to the corresponding parachain validators $\vals_\para$, along with any block metadata $(H(B'),\rin,\rout)$. 

\smallskip
% \paragraph{Parachain validator:}

Next each {\bf parachain validator} $V \in \vals_\para$ checks the validity of the block by evaluating the block with $\verify_\para(\blobB)$.  We refer to these as the {\em preliminary validity checks} as well.  We continue below if verification succeeds, but if verification fails, they reject the candidate $\blobB$ and reports it as invalid, ending its consideration.  We expect $V$ gossips $\blobB$ among the parachain validators $\vals_\para$, presumably after checking $\blobB$ itself.

\subsection{Relay chain phase} % Relay chain phase I: Block production 

% \smallskip
% \paragraph{Parachain validator:}

Now any {\bf parachain validator} $V \in \vals_\para$ runs $\encode_{f+1,\nvals}(\blobB)$ to obtain the list $\pieces'_B$ of $\nvals$ erasure code symbols aka pieces of $\blobB$.  Next $V$ computes a Merkle root $r_B$ for the Merkle tree with leaves $\pieces'_B$.  $V$ constructs the signed candidate receipt $\bar{r}_{B,\{V\}} := (\bar{r}_{B},\{V\})$ for $B$ by signing an inner candidate receipt $\bar{r}_B = (\para.\mathsf{id},H(\bar{r}_{B'}),r_B,H(B),\rin,\rout)$ where $B'$ denotes the parent of $B$, and attaching its signature.  
% TODO: Improve explicit state root commitments maybe?
% Also Joe asks if we should talk about parachain block headers
% Anything else?

We gossip these candidate receipts $\bar{r}_{B,S}$ among the parachain validators $\vals_\para$.  In doing so, we improve them by further aggregating the signature set $S$.\footnote{We envision $\vals_\para$ being small enough that BLS signatures do not improve verification time over Schnorr signatures, although BLS might reduce the candidate receipt's signature from 640 bytes down to 50 bytes.}  We publish $\bar{r}_{B,S}$ for relay chain block producers using relay chain gossip (mempool) whenever $S > \kappa_\para \npvals$, assuming this happens eventually.  We abandon $B$ however if another conflicting blocks gets finalised by GRANDPA.  We think $\kappa_\para = {1\over2}$ gives a reasonable choice.

\smallskip
% \paragraph{Relay chain block producer:}

Any upcoming {\bf relay chain block producer} $U \in \vals$ enqueues any candidate receipts $\bar{r}_{B,S}$ received for possible inclusion in some future relay chain block that $U$ creates (Definition \ref{def:header}), which we denote $R$.  We of course need $R$ to have an ancestor $R'$ that includes $\bar{r}_{B'} = \bar{r}_{B,S}.0.2$ and that no $R''$ between $R$ and $R'$ incude any block from $\para$.  Ideally $U$ continues aggregating the signatures $S$ on $\bar{r}_{B,S}$ while waiting its turn too, but $R$ must satisfy $|S| \ge \kappa$.  See \href{http://research.web3.foundation/en/latest/polkadot/BABE/Babe/}{BABE} for more details on block production.
% TODO: Any specific comments on relay chain block headers $\bh$


\subsection{Topology} 
%TODO: "Piece distribution topology" is too long

We find that scalability actually depends heavily upon the topology and routing used to distribute data, but that specifics depend upon the scale.  We briefly explain the specialised topology and routing requirements for our two phases of parachain data distribution.  We caution however that routing almost always requires some capacity for multi-hop forwarding because otherwise risks excluding some elected validators.  

\smallskip
% \paragraph{Candidate blocks:}

We need our network topology induced on one parachain $\para$ to distribute the $\blobB$s relatively quickly, which amounts to a graph expansion property.  We want a reasonable connectivity property too because too many parachain validators going down requires expensive reconstructions by any unreachable parachain validators (see \S\ref{sec:reconstructions} below).  We might also ask good collators to send the same block to several well chosen parachain validators as well.  As an example, if our parachain validators $\vals_\para$ form a cycle then $B$ reaches all parachain validators in two hops if the collators send $B$ to one third of $\vals_\para$, but adding well chosen chords reduces our connections with collators and improves our connectivity.  

\smallskip
% \paragraph{Candidate pieces:}

We define the candidate pieces $(d,r_B,\vect{r_B d})$ by attaching the Merkle root and an inclusion proof $\vect{rd}$ to each $d \in \pieces'_B$.  This makes each $d \in \pieces_B$ self authenticating, even if $S$ gets expanded later.
$$ \pieces_B = Listst{ (d,\bar{r}_{B,S},\vect{r_B d}) }{ d \in \pieces'_B } $$

We henceforth assume a relay chain block $R$ containing $\bar{r}_{B,S}$ exists.  We must distribute all the candidate pieces in $\pieces_B$ among the full relay chain validator set $\vals$ with $\pieces_B[i]$ going to $\vals[i]$ for $i = 1,\ldots,\nvals$, but only once $R$ exists.  All parachain validators in $\vals_\para$ must compute all of $\pieces'_B$ to compute $r_B$, from which computing $\pieces_B$ too costs nothing.  

We should therefore divide the distribution burden as equally as possible among parachain validators in $\vals_\para$.  We now outline an extremely simple topology that satisfies this requirement:

We recall any parachain $\para$ is equipped with a somewhat ephemeral value $\para.\mathsf{seed}$ that depends upon its parachain validator assignment and some on-chain randomness $r$.
$$ \para.\mathsf{seed} := H\left( r, \mathsf{sort} \setst{ V.\mathsf{pk} }{ V \in \vals_{\para_i} } \right) $$
If $\para_1$ and $\para_2$ are parachains then we let $\mathsf{parashuffle}(\para_1,\para_2)$ denote the Fisher-Yates shuffle of $\vals_{\para_i}$ seeded by $H( \para_i.\mathsf{seed}, \para_{2-i}.\mathsf{seed} )$.  Assume $\para_1$ and $\para_2$ are distinct parachains with disjoint validator sets.  We ask $\mathsf{parashuffle}(\para_1,\para_2)[j]$ to maintain a QUIC connection to $\mathsf{parashuffle}(\para_2,\para_1)[j]$ for $j = 1,\ldots,\npvals$.  

We can adapt this scheme to $|\vals_{\para_i}|$ quite easily if $\npvals$ turns out not to be well defined.  We can also do additional shuffles if more than one link is desired.  If assigned nodes cannot connect, then any still online attempt connections with some random other nodes from the other parachain, or perhaps use some smarter scheme. 

In more concrete terms, after our parachain validator $V$ of $\para$ observes some relay chain block $R$ containing $\bar{r}_{B,S}$ then, for all other parachains $\para' \ne \para$, $V$ computes $i_{\para'}$ such that $V = \mathsf{parashuffle}(\para,\para')[j]$ and $\vals[i_{\para'}] = \mathsf{parashuffle}(\para',\para)[j]$ for some $j \leq \npvals$, and $V$ send $\pieces_B[i_{\para'}]$ to $\vals[i_{\para'}]$ directly using QUIC.  We expect $\vals[i_{\para'}]$ might have some piece from $\para'$ for $V$ too, thanks to the symmetry of our $\mathsf{parashuffle}$ criteria.  We expect this symmetry to reduce the required connections by almost a factor of two.

We have described this as $V$ initiating the connection, but a similar procedure works for $V$ requesting its piece for some $\para'$ block, or symmetrically $\vals[i_{\para'}]$ requesting $\pieces_B[i_{\para'}]$.  In fact, an initial implementation should focus upon requests because as noted above we shall request from other validators when our first choice fails. 

If $\vals[i_{\para'}]$ cannot reach $V$ then $\vals[i_{\para'}]$ must select some backup node to replace $V$.  We should distribute these evenly among $\vals_\para \setminus \{V\}$, so as one option $\vals[i_{\para'}]$ could perform a Fisher-Yates shuffle of $\vals_\para \setminus \{V\}$, seeded by its own identity $\vals[i_{\para'}].\mathsf{pk}$ and $\para.\mathsf{seed}$, and then contact those remaining parachain validators in the resulting order.  We caution this option breaks the topology's symmetry, so as noted above nodes might exploit whatever links work first, and only take guidance from this shuffle when creating new links.  

We admitted adversarial manipulation of our network topology here, but it sounds acceptable for our availability scheme.  We shall consider whether this impacts gossip protocols in future work. 
% TODO:  Future work?  Here below?


\subsection{Availability} % GRANDPA
\label{sec:availability}

We integrate our availability and secondary validity check protocols directly with GRANDPA, in that an honest node $U \in \vals$ should not vote in GRANDPA for some relay chain block $R$ unless for all candidate receipts $\bar{r}_{B,S}$ in $R$,
\begin{itemize}
\item $U$ possesses their own piece from $\pieces_B$, and also
\item $U$ witnessed enough secondary checks for $\bar{r}_{B,S}$,
 as discussed blow in \S\ref{sec:validitycheck}.
\end{itemize}

We run these availability and secondary validity check protocols only for parachain blocks included in relay chain blocks, not for all parachain blocks proposed by parachain validators.  In this way, we reduce the damage done by spammy parachains, at least beyond their own assigned parachain validators.

At the same time, we avoid complex anti-spam or prioritisation logic since only GRANDPA requires this prior voting restriction.  In fact, if we later require prioritisation logic then this trick isolates it inside relay chain block production.
% TODO:  Any more details on GRANDPA integration?


\subsection{Unavailability} % BABE
\label{sec:unavailability}

We cannot entirely escape the availability question within BABE however:  We have several forks $C_1,\ldots,C_k$ for which at most $f$ validators possess all their chunks, but no fork for which $f+1$ validators possess all their chunks.  Yet, each block producers $U$ possess all their chunks for at least one fork $C_i$.  If BABE were oblivious to availability, then $U$ extends $C_i$, and GRANDPA stalls under this configuration. 
% TODO:  Anything about secondary validity check here ???

Instead, we define an availability grace period $\grace$ after which an unavailability subprotocol alters BABE's chain selection rule:  

If a validator $U \in \vals$ cannot obtain some piece $d \in \pieces_B$ within $\grace$ time after seeing the candidate receipt $\bar{r}_{B,\cdot}$ included in some relay chain block $R$, then $U$ announces via gossip the unavailability of the piece $d$. 
% TODO: Was $R_{head}$ but really?

We now explain validators' responses to these unavailability announcements:

First, suppose some validator $V \in \vals$ observes an unavailability announcement for some candidate receipt $\bar{r}_{B,S}$ from some validator $\vals[i]$.  If $V$ possesses the block $\blobB$ then $U$ has computed $\pieces_B$ to check $\bar{r}_{B,S}$, so $V$ already possesses $\pieces_B[i]$ and should offer it to $\vals[i]$.  Any $V \in S$ satisfies this, but so do any validators who signed off on the secondary checks discussed below in \S\ref{sec:validity}. 

Second, if any validator $U \in \vals$ observes unavailability announcements for pieces of some candidate receipt $\bar{r}_{B,\cdot}$ from at least $f+1$ different validators, then $U$ shall not propose relay chain containing $\bar{r}_{B,\cdot}$ in BABE.
In this situation, there might be prevotes but never any precommits in GRANDPA for chains containing  $\bar{r}_{B,\cdot}$, so $\bar{r}_{B,\cdot}$ cannot possibly be finalised by GRANDPA.  We should consider if the GHOST chain weighting rule used by BABE and by GRANDPA for prevotes should weigh unavailability announcements, but doing so should only impact performance.

As an aside, we also considered $U$ abandoning any fork $C$ for which at least $f+1$ different validators gossiped unavailability announcements for possibly distinct blobs in $C$, instead of for the same blob.  Any truly unavailable pieces eventually trigger both conditions but they trigger this variant with possibly distinct blobs first, and with more false positives.  We optimise for the honest case here and caution that more false positives results in more chains, so spammy parachains create could more load on the availability system.

Any validator should revoke their past unavailability announcements for some piece $d \in \pieces_B$ whenever they eventually obtain $d$, again by gossiping the revocation.  We also define some super availability grace period, longer than $\npvals \grace$, after which time, if $2 f + 1$ of the validators announced unavailability of some specific piece, then the parachain validators who signed for that block are slashed.
We revert this slash whenever revocations later reduce the unavailability announcements below $f+1$.
% TODO: Any interactions with slashing computation?










\subsection{Validity}
\label{sec:validity}

We have now excluded the block headers whose pieces are missing, thanks to the availability and unavailability protocols, at least under the ambiant assumptions for BABE and GRANDPA.



With the unavailability protocol, we can detect the block headers whose pieces are missing. Beyond this, we also need to detect whether invalid block headers are in the relay chain blocks. For example, if all parachain validators are malicious, they can sign for an invalid block. We can catch this only by reconstructing the blob with the available pieces. In the validity check protocol, we describe how extra validators (different from parachain validator) are assigned to check the validity of blocks and how malicious activities are detected.


We first give some parameters before giving the details of the protocol.
The first parameter $\vcheck$ defines the total number of validator checks needed for a block header.

$$\vcheck = \npvals + \mu +\lceil \runav + \rinv \rceil$$

Here, $\mu$ specifies the minimum number of checks, $\runav$ is the unavailability report factor from collators and $\rinv$ is the invalidity report factor from fishermen who claim invalidity for the relevant block. 


%Here, $\mu$ specifies the minimum number of checks, $\runav$ is the unavailability report factor which is the constant $c_a$ multiplied with the rate of the unavailability report in the last 1000 blocks.
%$\rinv$ is the invalidity report factor which is the constant $c_f$ multiplied with the relative stake of fishermen who claim invalidity for the relevant block. 




There is a three-factor validity check during the availability protocol:


\begin{enumerate}

      
    \item \textbf{Fisherman Check:} All fishermen collect blobs from collators in order to check the validity all the time. Whenever they discover an invalid block, they announce it to the validators by signing their claim. These claims are added to the block list by the validators. So, these claims are going to be in the relay chain. They do not provide any proof. If their claims are wrong then they are slashed. Otherwise, they are rewarded. The correctness of the fishermen claims is determined with the validity check protocol.
    
    \item \textbf{Parachain Validator Check:} All parachain validators check the validity of the block as described in the parachain phase of the availability protocol. If one parachain validator $PV_i$ sees that an invalid block header is in a block of the best relay chain, then he announces the invalidity. If a parachain validator has never seen the blob of the block header in the relay chain or he does not sign for that block, he runs the extra validity check protocol given below.
    
    \item \textbf{Non-Parachain Validator Check:} The extra validity checks are done by the non-parachain validators. Now, we explain how these validators are selected.
    
    \paragraph{Selection:} The selection process is private and no one knows the selected ones until they make it public. Assume that there exists $m$ parachains in Polkadot. Each validator $V_j$ checks first the following if required extra check is more than $n/m$ (i.e., $\mu + \lceil r_a + r_f \rceil \geq n/m$): 
    
    \begin{equation}\label{cond:mod}
        ID_{PC} = \mathtt{VRF}_{\sk^v_{j}}(r_{t}) \mod m    
    \end{equation}
     Here, $ID_{PC} \in \mathbb{N}$ is the identifier of a parachain $PC$ and $r_{t}$ is the VRF randomness of the block producer of slot $t$ in the relay chain (See \href{http://research.web3.foundation/en/latest/polkadot/BABE/Babe/}{BABE} for the details of $r_t$). For the current time $T$ where $T > \grace$, if  less than $\vcheck$ amount of checks are completed with condition (\ref{cond:mod}) or $\mu + \lceil r_a + r_f \rceil < n/m$ , each validator $V_j$ checks the following condition:
     \begin{equation}\label{cond:time}
        H(ID_{PC} || \mathtt{VRF}_{\sk^v_j}(r_t)) < \frac{\mu + \lceil r_a + r_f \rceil - \theta}{\nvals-\npvals}+\tau  
    \end{equation}
    
      where $\tau = T- \grace$ and $H$ is a hash function that maps a value between 0 and 1. Here, if $\mu + \lceil r_a + r_f \rceil \geq n/m$, $\theta$ is the number of validators in condition (\ref{cond:mod}) for $ID_{PC}$. Otherwise, $\theta = 0$.
    
    However, if a block producer produces multiple blocks with the same VRF randomness $r_t$ (equivocation), then a validator $V_j$ is selected for the extra check if one of the  below two conditions together with (\ref{cond:mod}) and (\ref{cond:time}) are satisfied:
    
    
    \begin{equation}\label{cond:modequiv}
         ID_{PC} = \mathtt{VRF}_{\sk^v_{j}}(r_{t}||H_B) \mod m
    \end{equation}
    
    \begin{equation}\label{cond:equiv}
         H(ID_{PC} || \mathtt{VRF}_{\sk^v_j}(H_{B})) < \frac{\vcheck - \npvals}{\nvals-\npvals}   
    \end{equation}
    
     where $H_B$ is the hash of the relay chain block whose VRF randomness is $r_t$. Remark that we have greater number of checks for equivocation because it is a sign of malicious activity. Malicious validators can see who is in condition (\ref{cond:mod}) or (\ref{cond:time}) and if there is  no honest validator with the conditions (\ref{cond:mod}) or (\ref{cond:time}), they can equivocate which includes an invalid block. Therefore, we need different conditions than the condition (\ref{cond:mod}) and the condition (\ref{cond:time}).
    
    When $V_j$ satisfies the condition (\ref{cond:mod}), (\ref{cond:time}), (\ref{cond:modequiv}) or (\ref{cond:equiv}), $V_j$ has a right to check the validity. For this, it follows the extra validity check protocol.
    
    We note that if number of $\vcheck$ validators satisfy the condition (\ref{cond:mod}) or (\ref{cond:time} ) for a parachain with the identifier $ID_{PC}$ and no equivocation exist, then satisfying condition (\ref{cond:modequiv}) or (\ref{cond:equiv}) does not get rewarded.
    
\end{enumerate}


\paragraph{Extra Validity Check:}
An assigned validator $V_j$  asks for the blob for the extra validity check or the erasure code pieces in the following order until receiving all information to check the validity of the block header:
\begin{enumerate}
    \item Parachain validators who signed for it: asked for the blob
    \item Other parachain validators who did not sign for it: asked for the blob
    \item Validators: asked for the erasure code piece with the proof. Assuming that $V_j$ has a set $\pieces'$ of a correct erasure codes where $|\pieces'|<k$. He asks for at least number of $k-|\pieces'|$ pieces in $\pieces\setminus \pieces'$ from the validators.
    
    \item Collators: asked for the erasure codes or the blob. We note that $V_j$ can ask for the blob or the erasure code, if he is connected to the collators network.
    
\end{enumerate}

In the end,  if $V_j$'s attempt in option 1 and 2 above is unsuccessful and obtains one third of the missing pieces instead of blob $\blobB$, he adds them to some set $\pieces''$ and reconstructs  $\blobB = (B,\pi,M)$ with the algorithm $\decode_{f+1,\nvals}(\pieces'')$. 

In any case, either obtaining $\blobB$ from $PV$s or the reconstruction algorithm, $V_j$ checks the validity of the block by  running  $\verify(\blobB)\rightarrow b$.
\begin{itemize}
    \item if $b = 0$ (the blob is invalid), $V_j$ signs that the block is invalid. Whenever a validator receives a valid signature from another validator saying that the block is invalid, this validator obtains the blob  the same way that extra validators obtain and follow the same process.
    \item if $b = 1$ (the blob is valid), $V_j$ signs that the block is valid. $V_j$ also  runs the $\encode_{f+1,\nvals}((B,\pi,M))$ to obtain the erasure codes $\pieces = \{d_1,d_2,...,d_n\}$ and constructs a Merkle tree  whose leaves are $d_1,d_2,...,d_n$. In the end, he gives away the missing piece of the validator with the Merkle tree proof whenever a validator announces unavailability. 
\end{itemize}


In the end of the validity protocol, if at least $f+1$ signatures are given by the validators saying that the block is invalid, then it is considered as invalid.
\subsection{Slashing and Rewarding}

\underline{\textbf{Fisherman}} 

\emph{Slashing:} If at least $\vcheck$ validators sign saying that the block is valid, then fishermen with the claim saying the block is invalid are slashed. All the claims from these fishermen are ignored in future.

\emph{Rewarding:} If $f+1$ validators sign to say the block is invalid, the  fishermen with the claim saying that the block is invalid are rewarded.

%TODO MORE DETAILS

\noindent\underline{\textbf{Validators}}

\emph{Slashing:} If at least $f+1$ validators sign for the invalidity of a block and less than $f+1$ validators sign for the validity of the block, then we slash all validators who signed for the validity.

If at least $f+1$ validators sign for the validity of a block and less than $f+1$ validator sign for invalidity, we slash the ones who signs for the invalidity.

We note that $f+1$ validity signatures and $f+1$ invalidity signatures are not possible given that at most $f$ validators are malicious and proof of block algorithms  are correct (See Definition \ref{def:pob}).

\emph{Rewarding:} All parachain validators and extra validators who signed for the final decision (either valid or invalid) of a block receive a reward. 

Eligibility of the reward can be easily checked for the parachain validators and extra validators who satisfies the conditions when $\tau = 0$. Latter, we just need to verify the VRF proof.
However, it is not easy to verify the condition for $\tau > 0$, because this value is subjective. Therefore, we may not need to be very precise for this $\tau$ value, if the signature of the validator is correct.
