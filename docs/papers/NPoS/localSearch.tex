\section{Enabling proportional justified representation}\label{s:local}

Suppose that we know of an efficient algorithm with good guarantees for maximin support but no guarantee for PJR, or we happen to know of a high quality solution in terms of maximin support but we ignore if it satisfies PJR. Can we use it to find a new solution of no lesser quality which is also guaranteed to satisfy PJR? And can we efficiently prove to an untrusting verifier that the new solution indeed satisfies PJR? 

In this section, we answer these questions in the positive for the first time. We present a simple local search procedure that takes an arbitrary feasible solution as input, and iteratively applies the heuristic presented in the previous section, where one candidate gets swapped in each round. The procedure always maintains or increases the value of the minimum member support, hence the quality of the solution in terms of the maximin support objective is maintained. Furthermore, as the procedure converges to a locally optimal solution, it is guaranteed to eventually satisfy the PJR property. 
We remark that testing whether an arbitrary solution satisfies PJR is known to be coNP-complete~\cite{aziz2018complexity}; in contrast, we describe an efficiently verifiable property that implies PJR (but is not a necessary condition for it), and which is satisfied by the output of our procedure.
As we did in Section~\ref{ss:heuristic}, when describing algorithms in this section we assume that there is a known background instance $(G=(N\cup C, E), s, k)$ that does not need to be passed as input.

\subsection{A parameterised version of proportional justified representation}

We start by defining a parameterised version of the PJR property, that measures just how well represented the voters are by a given committee $A$. It is a generalization of the property which turns it from binary to quantitative.

\begin{definition}
For any $t\in\R$, a committee $A\subseteq C$ (of any size) satisfies Proportional Justified Representation with parameter $t$ ($t$-PJR for short) if there is no group $N'\subseteq N$ of voters and integer $0<r\leq |A|$ such that:
\begin{itemize}
\item[a)] $\sum_{n\in N'} s_n \geq r\cdot t$,
\item[b)] $|\cap_{n\in N'} C_n|\geq r$, and
\item[c)] $|A\cap (\cup_{n\in N'} C_n)|<r$.
\end{itemize}
\end{definition}

In words, if there is a group $N'$ of voters with at least $r$ commonly approved candidates, who can afford to provide these candidates with a support of value $t$ each, then this group is represented by at least $r$ members in committee $A$, though not necessarily commonly approved. Notice that the standard version of PJR is equivalent to $\hat{t}$-PJR for $\hat{t}:=\sum_{n\in N} s_n / |A|$ (see Section~\ref{s:prel}), and that if a committee satisfies $t$-PJR then it also satisfies $t'$-PJR for each $t'\geq t$, i.e.~the property gets stronger as $t$ decreases. 

For instance, in the example described in Figure~\ref{fig:phragmen}, the optimal committee satisfies $(1/H_k)$-PJR, while the output of $\phragmen$ does not even satisfy $1$-PJR. However, since in this case we have that $\hat{t}=\frac{k+(1/H_k)}{k}=1+\frac{1}{k\cdot H_k}>1$ and the output does satisfy $\hat{t}$-PJR, it narrowly satisfies PJR. This example shows how much more expressive our parameterized definition of PJR is to assess the quality of a committee. 

We remark that in~\cite{sanchez2017proportional} the related notion of \emph{average satisfaction} is introduced, also to quantify the level of proportional representation achieved by a committee. Roughly speaking, this notion measures the average number of representatives in the committee that each voter in a group has, for any group of voters with sufficiently high vote strength and cohesiveness level. 
In contrast, with parameterized PJR we focus on providing sufficient representatives to the group as a whole and not to each individual voter, and we measure the required vote strength for a group to achieve it.
Interestingly, the average satisfaction measure is closely linked to the property of extended justified representation (EJR)~\cite{aziz2017justified}, and in~\cite{aziz2018complexity} the notion average satisfaction is used to prove that a local search algorithm achieves EJR. 
Similarly, we use parameterized PJR to prove that a local search algorithm achieves (standard) PJR.

We provide next a sufficient condition for a committee to satisfy $t$-PJR, based on our definitions of pre-score and score.  

\begin{lemma} \label{lem:locality}
If for a feasible solution $(A,w)$, there is a parameter $t\in\R$ such that $\max_{c'\in C\setminus A} prescore_w(c',t)<t$, or equivalently, such that $\max_{c'\in C\setminus A} score_w(c') <t$, then committee $A$ satisfies $t$-PJR.
\end{lemma}

\begin{proof} 
We prove the contrapositive of the claim. If $A$ does not satisfy $t$-PJR, there must be a subset $N'\subseteq N$ of voters and an integer $r>0$ that observe points a) through c) in the definition above. By points b) and c), set $(\cap_{n\in N'} C_n)\setminus A$ must be non-empty: let $c'$ be a candidate in it. We claim that for any feasible weight vector $w\in \R^E$, it holds that $prescore_w(c',t)\geq t$, and consequently $score_w(c')\geq t$ by the definition of score. We have
%
\begin{align*} prescore_w(c',t) &= \sum_{n\in N_{C'}}  slack_w(n,t) \\
&= \sum_{n\in N_{c'}} \Big(s_n - \sum_{c\in A\cap C_n} w_{nc}\cdot \min\Big\{1, \frac{t}{supp_w(c)}\Big\}\Big) \\
&\geq \sum_{n\in N'} \Big(s_n - t\cdot \sum_{c\in A\cap C_n} \frac{w_{nc}}{supp_w(c)}\Big) & (\text{as } N'\subseteq N_{c'})\\
&= \sum_{n\in N'} s_n - t\cdot \sum_{c\in A\cap(\cup_{n\in N'} C_n)} \frac{\sum_{n\in N'\cap N_c} w_{nc}}{\sum_{n\in N_c} w_{nc}} 
& (\text{where fraction is } \leq 1)\\ 
&\geq t\cdot r - t\cdot |A\cap (\cup_{n\in N'} C_n)| & (\text{by a)})\\
& \geq t\cdot r - t\cdot (r-1) = t & (\text{by c)}). \end{align*}
%
This proves that $prescore_w(c',t) \geq t$ and completes the proof of the lemma.
\end{proof}

We remark that for a given solution $(A,w)$ and parameter $t$, one can verify the condition defined in the previous lemma by running Algorithm~\ref{alg:maxprescore} in time $O(|E|)$ and checking whether $\maxprescore(A,w,t)<t$. This verification is thus linear in the size of the background instance. Alternatively, from just solution $(A,w)$ one can execute $\maxscore(A,w)$ in time $O(|E|\cdot \log k)$ (see Lemma~\ref{lem:maxscore2}) to obtain the highest score $t_{\max}$ and verify that $A$ satisfies $t$-PJR for each $t>t_{\max}$.

\subsection{The local search algorithm}

Assume that we are given a feasible solution $(A,w)$ with $|A|=k$. Our proposed PJR enabler, described in Algorithm~\ref{alg:localpjr}, executes the following local search. 
While there is a candidate $c'\in C\setminus A$ with $score_w(c')>supp_w(A)$, we remove from the solution a member with least support, insert $c'$, and repeat. 
By doing so, we will converge to a solution whose $t$-PJR parameter is as high as its least member support. 
To make this point precise, for any $\eps>0$ we say that a solution $(A,w)$ is \emph{$\eps$-close to locally optimal} if $A$ satisfies $t$-PJR for $t:=(1+\eps)\cdot supp_{w}(A)$. 
Notice then that the minimum support $supp_{w}(A)$ of solution $(A,w)$ will always be smaller than $\hat{t}=\sum_{n\in N} s_n / |A|$, 
so by Lemma~\ref{lem:locality} if the solution $(A,w)$ is close enough to being locally optimal, it will satisfy $\hat{t}$-PJR and thus the PJR property.

\begin{algorithm}[htb]\label{alg:localpjr}
\SetAlgoLined
\KwData{Full feasible solution $(A,w)$, parameter $\eps>0$.}

Let $\hat{t}\leftarrow \sum_{n\in N} s_n / |A|$\;
\While{True}{
  Find tuple $(c_{\min}, t_{\min})$ so that $c_{\min}\in A$ and $t_{\min}=supp_w(c_{\min})=supp_w(A)$\;
  Define partial solution $(\bar{A}, \bar{w})$ where $\bar{A}\leftarrow A-c_{\min}$, $\bar{w}\leftarrow w$, and $\bar{w}_{nc_{\min}} \leftarrow 0$ for each $n\in N_{c_{\min}}$\;
  Let $(c_{\max},t_{\max})\leftarrow \maxscore(\bar{A},\bar{w})$\;
  \lIf {($t_{\max}< t_{stop}\leftarrow \min\{ (1+\eps)\cdot t_{\min}, \hat{t}\}$)} {
    %Ensure feasibility of $(A,w)$ (equation~\ref{eq:feasible}) by increasing some weights in $w$\;
    \Return $(A,w)$
  }
  Update $(A,w)\leftarrow \ins(\bar{A},\bar{w},c_{\max},t_{\max})$\;
}
\caption{$\LSPJR(A,w,\eps)$}
\end{algorithm}

\begin{theorem}\label{thm:enabler}
For any parameter $\eps>0$ and a feasible full solution $(A,w)$, let $(A',w')$ be the output solution to $\LSPJR(A,w,\eps)$. Then: 
\begin{enumerate}
    \item solution $(A',w')$ is feasible and full, and $supp_{w'}(A')\geq supp_w(A)$; \label{item:support}
    \item solution $(A', w')$ satisfies the condition on Lemma~\ref{lem:locality} for parameter $t=\min\{(1+\eps)\cdot supp_{w'}(A'), \hat{t}\}$, where $\hat{t}=\sum_{n\in N} s_n / k$, and consequently \label{item:tPJR}
    \begin{enumerate}
        \item solution $(A',w')$ is $\eps$-close to locally optimal, and
        \item $A'$ satisfies standard PJR; \label{item:PJR}
    \end{enumerate}
    \item if $(A,w)$ has an $\alpha$-approximation guarantee for the maximin support objective, for some parameter $\alpha\geq 1$, then the algorithm performs at most $k\cdot (1+\log_{1+\eps} \alpha)+1$ iterations, each taking time $O(|E|\cdot \log k)$; and \label{item:iterations}
    \item from the $k$-th iteration onward, the current solution is guaranteed to satisfy PJR. \label{item:infinity}
\end{enumerate}
\end{theorem}

Notice that the last statement establishes that Algorithm $\LSPJR$ can be executed as a post-computation along any algorithm for maximin support, in time $O(|E|\cdot k\log k)$. Hence, the complexity of such post-computation is dominated by the complexity of all constant-factor approximations presented in this paper.

\begin{proof}
We prove point~\ref{item:support} by induction on the iterations. 
We use $i$ as a superscript to indicate the value of the different variables at the beginning of the $i$-th iteration. 
If $|A^i|=k$, then $|\bar{A}^i|=k-1$ and $|\bar{A}^{i+1}|=k$ once again. 
If vector $w^i$ is feasible, then so will be vectors $\bar{w}^i$ and $w^{i+1}$. Furthermore, it is clear that $supp_{\bar{w}^i}(\bar{A}^i)\geq supp_{w^i}(A^i)=t^i_{\min}$, and by definition of $\hat{t}$ and an averaging argument, $t^i_{\min}$ is always upper bounded by $\hat{t}$, and hence $t^i_{stop} = \min\{ (1+\eps)t^i_{min}, \hat{t} \} \geq t^i_{\min}$. Thus, it follows from Lemma~\ref{lem:insert} and from the stopping condition that 
$$supp_{w^{i+1}}(A^{i+1}) \geq \min\{ supp_{\bar{w}^{i}}(\bar{A}^{i}), t^i_{\max} \}\geq \min\{ t^i_{\min}, t^i_{stop}\} = t^i_{\min}=supp_{w^i}(A^i). $$

This proves point~\ref{item:support}. 
Assume now that the algorithm terminates on iteration $T$. By the stopping condition, we have that $t^T_{\max}=\max_{c\in C\setminus A^T} score_{w^T}(c) < t^T_{stop}$. 
Thus by Lemma~\ref{lem:locality} the output committee $(A^T, w^T)$ satisfies $t^T_{stop}$-PJR, where $t^T_{stop}=\{(1+\eps)\cdot supp_{w^T}(A^T), \hat{t}\}$. This proves point~\ref{item:tPJR} and its two sub-claims.

We continue to point \ref{item:iterations}. Each iteration is dominated in complexity by the call to Algorithm $\maxscore$, which takes time $O(|E|\cdot \log k)$ by Lemma~\ref{lem:maxscore}. Hence, it remains to prove that the algorithm terminates in $T\leq k\cdot (1+\log_{1+\eps} \alpha)+1$ iterations. To do that, we analyse the evolution of the least member support $t^i_{\min}=supp_{w^i}(A^i)$. First, we argue that if ever $t^i_{\min}=\hat{t}$, then the algorithm terminates immediately, i.e.~$i=T$. This is because in this case all members in $A^i$ must have a support of exactly $\hat{t}$, and all nominators have zero slack for $t= \hat{t}$, so all candidates in $C\setminus A^i$ have scores strictly below $\hat{t}$ and the stopping condition is fulfilled.

Next, we claim that for any iteration $i$ with $1\leq i<T-k$, we have $t^{i+k}_{\min}\geq (1+\eps)\cdot t^{i}_{\min}$. This is because in each iteration $j\geq i$, we are removing a member with least support while not adding new members with support below $t^j_{stop} \geq t^i_{stop}$. As there are only $k$ candidates, we must have that $t^{i+k}_{\min}\geq t^i_{stop}=\min\{(1+\eps)\cdot t^i_{\min}, \hat{t}\}$. Thus $t^{i+k}_{\min}$ is either at least $(1+\eps)\cdot t^i_{\min}$, or it is $\hat{t}$, but it cannot be the latter by the previous claim and the fact that $i+k<T$. This proves the claim. Therefore, if the algorithm outputs a solution $(A^T,w^T)$ and has an input solution $(A^1, w^1)$ with an $\alpha$-approximation guarantee for the maximin support objective, then 
$$\alpha\cdot supp_{w^1}(A^1) \geq supp_{w^T}(A^T) \geq (1+\eps)^{\lfloor (T-1)/k \rfloor} \cdot supp_{w^1}(A^1).$$
Hence, $\alpha\geq (1+\eps)^{\lfloor (T-1)/k \rfloor}$, and $T\leq k\cdot(1+\log_{1+\eps} \alpha)+1$. This completes the proof of point \ref{item:iterations}.

For point \ref{item:infinity}, we consider again the previous inequality $t^{i+k}_{\min}\geq t^i_{stop}=\min\{(1+\eps)\cdot t^i_{\min}, \hat{t}\}$, and we make $j:=i+k$ and $\eps\rightarrow \infty$: as long as the stopping condition is not observed, it must be the case that $t^{j}_{\min}\geq \hat{t}$ for any $k+1\leq j\leq T$, so the current solution observes PJR.
\end{proof}