\section{Algorithmic considerations of the new heuristic}\label{s:algorithms}

The goal of this section is threefold. 
First, we prove Theorem~\ref{thm:runtimes} and describe efficient algorithms related to the $\phragmms$ heuristic proposed in Section~\ref{s:heuristic}. 
Second, we compare it to $\phragmen$ (Algorithm~\ref{alg:phragmen}) and argue that the new heuristic can be seen as a natural progression in terms of algorithmic complication. 
Finally, we improve the runtime analysis of Algorithm $\balanced$ and show that each iteration can be executed in time $O(\bal + |E|)$, down from $O(\bal + |E|\cdot \log k)$ as was proved in Section~\ref{s:315}. 

As we did in Section~\ref{s:inserting}, we assume in the following that the election instance $(G=(N\cup C, E), s, k)$ is known and does not need to be given as input. Instead, the input is a partial solution $(A,w)$ with $|A|\leq k$. The list of committee member supports $(supp_w(c))_{c\in A}$ is implicitly passed by reference and updated in every algorithm.
We start with Algorithm~\ref{alg:maxprescore}, which shows how to find the candidate with highest pre-score for a given threshold $t$.

\begin{algorithm}[htb]\label{alg:maxprescore}
\SetAlgoLined
\KwData{Partial solution $(A,w)$, threshold $t\geq 0$.}
\lFor{each voter $n\in N$}{
compute $slack(n,t)=s_n-\sum_{c\in A\cap C_n} w_{nc}\cdot \min\{1, t/supp_w(c)\}$
}
\lFor{each candidate $c'\in C\setminus A$}{
compute $prescore(c',t)=\sum_{n\in N_{c'}} slack(n,t)$
}
Find a candidate $c_t\in\argmax_{c'\in C\setminus A} prescore(c', t)$\;
\Return $(c_t, prescore(c_t, t))$\;
 \caption{$\maxprescore(A,w,t)$}
\end{algorithm}

\begin{lemma}
For a partial solution $(A,w)$ and threshold $t\geq 0$, $\maxprescore(A,w,t)$ executes in time $O(|E|)$, 
and returns a tuple $(c_t,p_t)$ such that $c_t\in C\setminus A$ 
and $p_t=prescore(c_t,t)=\max_{c'\in C\setminus A} prescore(c',t)$.
\end{lemma}

\begin{proof}
The correctness of the algorithm directly follows from the definitions of slack and pre-score. The running time is $O(|E|)$ because each edge in the approval graph $G=(N\cup V, E)$ is inspected at most once in each of the two loops. The first loop also inspects each voter, but we have $|N|=O(|E|)$ since we assume that $G$ has no isolated vertices.
\end{proof}


For a fixed partial solution $(A,w)$ and for each candidate $c'\in C\setminus A$, consider the function 
$f_{c'}(t):=prescore(c',t)-t$ in the interval $[0,\infty)$. 
Notice from the definition of pre-score~\eqref{eq:prescore} that this function is convex, continuous and strictly decreasing with no lower bound, and that $f_{c'}(0)\geq 0$; hence it has a unique root which corresponds precisely to $score(c')$. We could approximate this root via binary search -- however, we can do better. 
Function $f_{c'}(t)$ is piece-wise linear: if we sort the member supports $\{supp_w(c): \ c\in A\}=\{t_1, \cdots, t_r\}$ so that $t_1 < \cdots < t_r$ for some $r\leq |A|$, then $f_{c'}(t)$ is linear in each of the intervals $[0, t_1), [t_1, t_2), \cdots, [t_r, \infty)$.

Similarly, function $f(t):= \max_{c'\in C\setminus A} f_{c'}(t) = \max_{c'\in C\setminus A} prescore(c',t) -t$ is continuous and strictly decreasing in the interval $[0,\infty)$, with a unique root $t_{\max}=\max_{c'\in C\setminus A} score(c')$. Unfortunately, this function is in general not linear within each of the intervals above.%
%
\footnote{In each of these $O(k)$ intervals, function $f(t)$ is piece-wise linear with $O(|C|)$ pieces. We could thus find the root of $f(t)$ via binary search by performing $O(\log k + \log |C|)$ calls to $\maxprescore$. However, our approach only requires $O(\log k)$ such calls.} %
%
Still, it will be convenient to use binary search to identify the interval that contains $t_{\max}$. We do so in Algorithm~\ref{alg:interval}. The next lemma follows from our exposition and its proof is skipped.

\begin{algorithm}[htb]\label{alg:interval}
\SetAlgoLined
\KwData{Partial solution $(A,w)$.}
Sort the member supports to obtain $0=t_0<t_1<\cdots <t_r$, where $\{t_1, \cdots, t_r\}=\{supp_w(c): \ c\in A\}$\;
\lIf{$p_{t_r}\geq t_r$ where $(c_{t_r},p_{t_r})\leftarrow \maxprescore(A,w,t_r)$}{\Return $t_r$}
Let $j_{lo}=0$, $j_{hi}=r-1$\;
\While{$j_{lo}<j_{hi}$}{
  Let $j=\lceil (j_{lo}+j_{hi})/2 \rceil$\;
  \leIf{$p_{t_j}\geq t_j$ where $(c_{t_j},p_{t_j})\leftarrow \maxprescore(A,w,t_j)$}{
  Set $j_{lo}\leftarrow j$}{
  Set $j_{hi}\leftarrow j-1$}
}
\Return $t_{j_{lo}}$\;

 \caption{$\interval(A,w)$}
\end{algorithm}

\begin{lemma}\label{lem:interval}
For a partial solution $(A,w)$, Algorithm $\interval(A,w)$ makes $O(\log |A|)$ calls to $\maxprescore$, and thus runs in time $O(|E|\cdot \log k)$. It returns a value $t'$ so that $t'\leq t_{\max}:=\max_{c'\in C\setminus A} score(c')$, and for each candidate $c'\in C\setminus A$, the value of $prescore(c',t)$ is linear in $t$ within the interval $[t',t_{\max}]$.
\end{lemma}

Once we have identified such a value $t'$, we exploit the fact that for each $c'\in C\setminus A$, function $f_{c'}(t)$ is linear inside the interval $[t',t_{\max}]$. If we fix a candidate $c'$ and linearize function $f_{c'}(t)$ by extending its linear behavior within $[t', t_{\max}]$ onto the full domain $[0,\infty)$, and we denote its corresponding unique root by $t_{c'}$, then we have 
%
\begin{align*}
    0&= f_{c'}(t_{c'})|_{\text{linearized around } [t', t_{\max}]}\\
    &=prescore(c', t_{c'})|_{\text{linearized around } [t', t_{\max}]} - t_{c'}\\
    &=\sum_{n\in N_{c'}} slack(n,t)|_{\text{linearized around } [t', t_{\max}]} - t_{c'}\\
    &=\sum_{n\in N_{c'}} \Big( s_n - \sum_{c\in A\cap C_n: \ supp_{w}(c)< t'}w_{nc} - \sum_{c\in A\cap C_n: \ supp_w(c)\geq t'} w_{nc}\cdot t_{c'}/supp_w(c) \Big) - t_{c'},
\end{align*}
%
where we used the definitions of pre-score and slack. Solving for $t_{c'}$, we obtain
%
\begin{align*}
    t_{c'}=\frac{\sum_{n\in N_{c'}} \Big( s_n - \sum_{c\in A\cap C_n: \ supp_w(c)< t'} w_{nc} \Big)}%
    {1+\sum_{n\in N_{c'}} \sum_{c\in A\cap C_n: \ supp_w(c)\geq t'} \frac{w_{nc}}{supp_w(c)}}=:linscore_{(A,w)}(c',t').
\end{align*}

Notice that the expression above depends only on $t'$ and not on $t_{\max}$. 
Replacing $t'$ by $x$ in the expression above, we define \emph{the linearized score of $c'$ around point $x$} (denoted by $linscore_{(A,w)}(c',x)$ and shortened to $linscore(c',t')$) for each candidate $c'\in C\setminus A$ and each $x\geq 0$. 
Since $f_{c'}(t)$ is a convex decreasing function over $[0,\infty)$ and its linearization around $x$ is a straight line tangential to it (meeting at point $x$), then the root of this linearization must fall to the left of its own root, i.e.~it holds that 
$$linscore(c',x)\leq score(c') \quad \quad \text{for each } c'\in C\setminus A \text{ and each } x\geq 0.$$
On the other hand, for the candidate $c_{\max}$ with highest score $t_{\max}$, and for $x=t'$ as in Lemma~\ref{lem:interval}, these two roots must coincide, i.e. $t_{\max}=score(c_{\max})=linscore(c_{\max}, t')$. 
Consequently, $c_{\max}$ also has the highest linearized score around $t'$ among all candidates in $C\setminus A$, and we can exploit this fact to find it. We formalize these observations in Algorithm~\ref{alg:maxscore} and the lemma below.

\begin{algorithm}[htb]\label{alg:maxscore}
\SetAlgoLined
\KwData{Partial solution $(A,w)$.}
Let $t'\leftarrow \interval(A,w)$\;

\For{each voter $n\in N$}{
Compute $p_n:=s_n-\sum_{c\in A\cap C_n: \ supp_w(c)< t'} w_{nc}$\;
Compute $q_n:=\sum_{c\in A\cap C_n: \ supp_w(c)\geq t'} w_{nc}/supp_w(c)$\;
}
\lFor{each candidate $c'\in C\setminus A$}{
compute $linscore(c',t')=\frac{\sum_{n\in N_{c'}} p_n}{1+\sum_{n\in N_{c'}} q_n}$}
Find a candidate $c_{\max}\in\argmax_{c'\in C\setminus A} linscore(c',t')$\;
\Return $(c_{\max}, linscore(c_{\max},t'))$\;
 \caption{$\maxscore(A,w)$}
\end{algorithm}

\begin{lemma}\label{lem:maxscore}
For a partial solution $(A,w)$, Algorithm $\maxscore(A,w)$ runs in time $O(|E|\cdot \log k)$ and returns a tuple $(c_{\max}, t_{\max})$ such that $t_{\max}=score(c_{\max})=\max_{c'\in C\setminus A} score(c')$.
\end{lemma}
\begin{proof}
The correctness of the algorithm follows from the definition of linearized score and the arguments above. Each of the \textbf{for} loops executes in time $O(|E|)$ because in each one of them each edge is examined at most once. Thus, the running time is dominated by the call to function $\interval(A,w)$, which takes time $O(|E|\cdot \log k)$.
\end{proof}

This completes the proof of Theorem~\ref{thm:runtimes}. 
We highlight again that an iteration of the $\phragmms$ executes in time $O(|E|\cdot \log k)$, almost matching the complexity of $\phragmen$ which is $O(|E|)$ time per iteration.

Next, we discuss the similarities and differences between the $\phragmms$ and $\phragmen$ heuristics. 
To this end, consider an execution of $\phragmms$ in the case that the input partial solution $(A,w)$ is balanced. 
In this case, by point 3 of Lemma~\ref{lem:balanced}, for each voter $n\in N$ and each member $c\in A\cap C_n$ such that $w_{nc}>0$ it must hold that $supp_w(c)=supp_w(A\cap C_n)$.  
If we then compute the linearized score of a candidate $c'\in C\setminus A$ around the origin (setting $x=0$) we obtain 
\begin{align*}
linscore(c',0)&=\frac{\sum_{n\in N_{c'}} s_n}
{1 + \sum_{n\in N_{c'}} \frac{1}{supp_w(A\cap C_n)} \sum_{c\in A\cap C_n} w_{nc}} \\
&=\frac{\sum_{n\in N_{c'}} s_n}{1 + \sum_{n\in N_{c'}} \frac{s_n}{supp_w(A\cap C_n)} },
\end{align*}
where in the second line we used the fact that $\sum_{c\in A\cap C_n} w_{nc}=s_n$ must hold for each voter $n$ for which $A\cap C_n\neq \emptyset$, by point 2 of Lemma~\ref{lem:balanced} (if $A\cap C_n=\emptyset$ then $supp_w(A\cap C_n)=\infty$ by convention and the corresponding term in the denominator vanishes). 
This linearized score corresponds precisely to the inverse of the candidate \emph{load} function being minimized in the $\phragmen$ heuristic (see Algorithm~\ref{alg:phragmen}), with a corresponding voter load function set to the inverse of $supp_w(A\cap C_n)$. 
Therefore, the two heuristics coincide in the specific case that the input partial solution is balanced and the linearized score around the origin is used. 
Put differently, we can say that the new heuristic provides two main advantages: 
First, by using edge weights it defines a more robust notion of loads, which enables it to deal with an arbitrary input partial solution without any guarantees on how it was constructed. 
Second, by considering further linearizations of the pre-score function it grants new candidates higher scores and thus adds them with higher supports.

Finally, we reconsider the complexity of $\balanced$ (Algorithm~\ref{alg:balanced}). 
At the start of each iteration with current partial solution $(A,w)$, notice by Lemma~\ref{lem:315localoptimality} that the highest score $t_{\max}$ must be lower than the least member support $t_1=supp_w(A)$. So, $t_{\max}$ lies in the interval $[0, t_1]$, and we can skip the computation of Algorithm $\interval(A,w)$ as we know that it would return $t'=0$. 
Without this computation, $\maxscore(A,w)$ (Algorithm~\ref{alg:maxscore}) runs in time $O(|E|)$, so the runtime of a full iteration of $\balanced$ can be performed in time $O(\bal + |E|)$, down from $O(\bal + |E|\cdot \log k)$ as was established in Section~\ref{s:315}.
