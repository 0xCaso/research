\section{A new heuristic}\label{s:heuristic}

In the previous section we established that the efficient $\phragmen$ heuristic~\cite{brill2017phragmen} fails to provide a good guarantee for the maximin support objective, whereas $\MMS$~\cite{sanchez2016maximin} guarantees a 2-factor approximation albeit with a considerably worse running time. 
In this section we introduce $\phragmms$, a new heuristic that is inspired in $\phragmen$ and maintains a comparable runtime, yet lends itself to more robust analyses both for maximin support and for PJR. 

\subsection{Inserting one candidate to a partial solution}\label{s:inserting}

We start with a brief analysis of the approaches taken in $\MMS$ and $\phragmen$. Both are iterative greedy algorithms that start with an empty committee and add to it a new candidate over $k$ iterations, following some specific rule for candidate selection.
For a given partial solution, $\MMS$ (Algorithm~\ref{alg:mms}) computes a balanced weight vector for each possible augmented committee resulting from adding a candidate, and keeps the one that offers the largest support. 
Such a heuristic offers strong guarantees for maximin support, but is relatively slow as computing balanced vectors is costly. 
On the other hand, the $\phragmen$ heuristic (Algorithm~\ref{alg:phragmen} in Appendix~\ref{s:phragmen}) forgoes balancing and replaces it with a ``lazy'' version that performs minimal modifications to the current weight vector, making it balanced only in the neighborhood around the newly inserted candidate. 
The $\phragmms$ heuristic takes a similar approach, but uses a slightly less lazy version of balancing, with a corresponding slight increase in runtime. 

In all algorithms described in this section, we assume that there is a known background instance $(G=(N\cup C, E), s, k)$ that does not need to be passed as input. Rather, the input is a partial solution $(A,w)$ with $|A|\leq k$. We also assume that the list of committee member supports $(supp_w(c))_{c\in A}$ is implicitly passed by reference and updated in every algorithm, so it does not need to be recomputed every time.
%
Let $c'\in C\setminus A$ be a candidate that we consider adding to $(A,w)$. To do so, we need to modify weight vector $w$ into a new feasible vector $w'$ that redirects towards $c'$ some of the votes of voters in $N_{c'}$, in turn decreasing the support of other committee members approved by these voters. Now, for a given threshold $t\geq 0$, we want to make sure not to reduce the support of any member $c$ below $t$, assuming it starts above $t$, and not to reduce it at all otherwise. A simple rule to ensure this is as follows: for each voter $n$ in $N_{c'}$ and each member $c\in A\cap C_n$, reduce the weight on edge $nc$ from $w_{nc}$ to $w_{nc}\cdot \min\{1, t/supp_w(c)\}$, and assign the difference to edge $nc'$. That way, it is clear that even if all edges incident to a member $c$ are so reduced in weight, the support of $c$ is scaled by a factor at most $\min\{1, t/supp_w(c)\}$ and hence its new support does not fall below $t$.

Thus, if for each $n\in N$ and $t\geq 0$ we define that voter's \emph{slack} as

\begin{align}
    slack_{(A,w)}(n,t):= s_n - \sum_{c\in A\cap C_n} w_{nc} \cdot\min \Big\{ 1, t/supp_w(c)\Big\} \label{eq:slack}
\end{align}
%
and for each $c'\in C\setminus A$ and $t\geq 0$ we define that candidate's \emph{pre-score} as
%
\begin{equation}\label{eq:prescore}
    prescore_{(A,w)}(c',t) := \sum_{n\in N_{c'}} slack_{(A,w)}(n,t),
\end{equation}
%
then we can add $c'$ to the solution with a support of $prescore_{(A,w)}(c',t)$, while not making any other member's support decrease below threshold $t$. The resulting weight modification rule is formalized in Algorithm~\ref{alg:ins}. The next lemma easily follows from the previous exposition and its proof is skipped.

\begin{algorithm}[htb]\label{alg:ins}
\SetAlgoLined
\KwData{Partial feasible solution $(A,w)$, candidate $c'\in C\setminus A$, threshold $t\geq 0$.}
Initialize $w'\leftarrow w$\;
\For{each voter $n\in N_{c'}$}{
Set $w'_{nc'} \leftarrow s_n$\;
\For{each member $c\in A\cap C_n$}{
\lIf{$supp_w(c)>t$}{update $w'_{nc} \leftarrow w'_{nc}\cdot\frac{t}{supp_w(c)}$}
Update $w'_{nc'}\leftarrow w'_{nc'} - w'_{nc}$\;
}
}
\Return $(A+c',w')$\;
 \caption{$\ins(A,w,c',t)$}
\end{algorithm}

\begin{lemma}\label{lem:insert}
For a feasible partial solution $(A,w)$, candidate $c'\in C\setminus A$ and threshold $t\geq 0$, 
Algorithm $\ins(A,w,c',t)$ executes in time $O(|E|)$ and returns a feasible solution $(A+c',w')$ 
where $supp_{w'}(c')=prescore_{(A,w)}(c',t)$ and $supp_{w'}(c)\geq \min\{supp_w(c),t\}$ for each member $c\in A$. 
In particular, if $prescore_{(A,w)}(c',t)\geq t$ then $supp_{w'}(A+c')\geq \min\{supp_w(A),t\}$.
\end{lemma}

Whenever partial solution $(A,w)$ is clear from context, we drop the subscript from our notation of slack and pre-score. 
When we add the new candidate $c'$ to the solution, we want to ensure that inequality $prescore(c',t)\geq t$ holds, as we want to avoid increasing the number of validators with support below threshold $t$. 
Thus, for each unelected candidate $c'\in C\setminus A$ we define its \emph{score} to be the highest value of $t$ such that $prescore(c',t) \geq t$ holds, i.e. 
%
\begin{align}
    score_{(A,w)}(c'):=\max\{t\geq 0: \ prescore_{(A,w)}(c',t)\geq t\},
\end{align}
%
where again we drop the subscript if $(A,w)$ is clear from context. Our heuristic now becomes apparent.

\begin{heuristic}[$\phragmms$]
Given a partial solution $(A,w)$, find a candidate $c_{\max}\in C\setminus A$ with highest score $t_{\max}=\max_{c'\in C\setminus A} score(c')$, and execute $\ins(A,w,c_{\max},t_{\max})$ so that its output solution $(A+c_{\max},w')$ observes 

$$\forall c\in A, \ supp_{w'}(c)\geq \min\{supp_w(c), t_{\max}\}, \quad \text{ and } \quad supp_{w'}(A+c_{\max})\geq \min \Big\{ supp_w(A), t_{\max}\Big\}.$$
\end{heuristic}

In Appendix~\ref{s:algorithms} we describe efficient algorithms to find the candidate with highest pre-score for a given threshold $t$, as well as the candidate with overall highest score.

\begin{theorem}\label{thm:runtimes}
For a partial solution $(A,w)$ and threshold $t\geq 0$, there is an algorithm $\maxprescore(A,w,t)$ that executes in time $O(|E|)$ and returns a tuple $(c_t,p_t)$ such that $c_t\in C\setminus A$ and $p_t=prescore(c_t,t)=\max_{c'\in C\setminus A} prescore(c',t)$.
Furthermore, there is an algorithm $\maxscore(A,w)$ that runs in time $O(|E|\cdot \log k)$ and returns a tuple $(c_{\max}, t_{\max})$ such that $t_{\max}=score(c_{\max})=\max_{c'\in C\setminus A} score(c')$.
\end{theorem}

We remark that our heuristic, which finds a candidate with highest score and adds it to the current partial solution (Algorithm $\maxscore$ followed by $\ins$) executes in time $O(|E|\cdot \log k)$. 
It thus matches up to a logarithmic term the running time of $\phragmen$ which is $O(|E|)$ per iteration; see Appendix~\ref{s:phragmen}. 
In Appendix~\ref{s:algorithms} we also draw parallels between the $\phragmen$ and $\phragmms$ heuristics, and explain how the latter can be seen as a natural complication of the former which always grants higher score values to candidates and thus inserts them with higher supports.

